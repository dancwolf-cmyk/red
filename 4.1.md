# 4. Experiments

This section presents a systematic empirical evaluation of the proposed **Residual Expert Decomposition (RED)** framework. All experiments are conducted under controlled numerical settings designed to isolate the effects of modular architecture, symbolic structure handling, and expert specialization.

RED employs a shared backbone encoder together with multiple lightweight expert modules. Each expert specializes in a distinct component of the arithmetic reasoning process—for example, numerical range discrimination or atomic arithmetic operations—allowing the system to express modular knowledge while maintaining a unified prediction interface. This design enables comprehensive evaluation along three key dimensions:

1. **Local specialization** — whether experts exhibit consistent behavior within their respective numerical or functional domains.
2. **Global recomposition** — whether the router effectively integrates expert outputs into coherent final predictions.
3. **Structural robustness** — whether modular components remain stable when added, removed, or replaced.

Based on these criteria, we investigate the following research questions:

- **RQ1 — Performance:** Does RED surpass global models, uniform ensembling, and classical MoE gating across arithmetic tasks?
- **RQ2 — Stability:** Do experts preserve consistent specialization patterns and does the router maintain balanced accuracy across numerical intervals?
- **RQ3 — Modularity:** Can independently trained experts be combined without retraining the backbone or interfering with one another?
- **RQ4 — Interpretability:** Does modular decomposition lead to more transparent and structured reasoning behavior?

Two arithmetic tasks are used to assess the framework:
1. **Single-step addition**, and  
2. **Multi-step mixed addition–subtraction expressions**.

The next section formally defines these tasks and the reasoning structures they require.
---
### **Task 1: Single-Step Addition**

Task 1 evaluates reasoning over a single explicit arithmetic operation. Given an input such as:

> “What is 12 plus 27?”

The system must:
1. parse the linguistic structure of the query,
2. identify the arithmetic operator,
3. compute the numerical result, and
4. assign the result to its corresponding numerical interval.

Operands follow a uniform sampling rule:

> a, b ∈ [2, 50], s = a + b ∈ [2, 100].

The output space is partitioned into five numerical intervals:
- **R1:** 2–20  
- **R2:** 21–40  
- **R3:** 41–60  
- **R4:** 61–80  
- **R5:** 81–100

This task establishes a clean and controlled setting for analyzing basic arithmetic behavior.
---
### **Task 2: Multi-Step Mixed Arithmetic**

Task 2 introduces multi-step expressions involving both addition and subtraction. Queries may include 2–4 operations, such as:
- “12 minus 5 plus 9”
- “29 minus 11 minus 9 plus 15”
- “18 plus 7 minus 3”

To solve a query, the system must:
1. infer the operator sequence from natural language,
2. apply operations in left-associative order,
3. compute the final numerical result,
4. map the result to one of the five numerical intervals.

Operands satisfy:

> xᵢ ∈ [2, 50], y = f(x₁, x₂, …, xₙ) ∈ [2, 100].

This task evaluates the model’s ability to maintain reasoning consistency as symbolic complexity increases.
---
### **Two Execution Paradigms for Task 2**

Task 2 can be evaluated under two complementary execution modes.

#### **(1) End-to-End Reasoning (Implicit Structure Inference)**
The model must infer:
- the computation structure,
- the operator sequence,
- and the interval of the final result.

This mode tests whether a model can induce internal reasoning structure directly from language.

#### **(2) Decomposed Execution via a Step Decomposer (Explicit Structure Guidance)**
A separate step decomposer generates an explicit program, for example:
```
Step 1: 18 + 7 = x1
Step 2: x1 − 3 = x2
```
Arithmetic experts then execute the program deterministically.

This setting separates structural inference from numerical execution, enabling analysis of each component independently.
---
### **Summary**

Task 2 therefore supports two reasoning regimes:
1. **Implicit execution**, where the system must infer both structure and result; and
2. **Explicit execution**, where structure is provided, allowing examination of numerical execution capability.

This dual formulation enables controlled evaluation of structure learning, modular reasoning, and execution fidelity across different levels of symbolic complexity.